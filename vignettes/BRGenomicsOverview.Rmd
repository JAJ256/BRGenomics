---
title: "Basepair-Resolution Analysis with BRGenomics"
subtitle: "_Straightforward and efficient tools for analyzing genomics data_"
author:
  name: Mike DeBerardine
  email: mike.deberardine@gmail.com
package: BRGenomics
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
    toc_depth: 1
  BiocStyle::pdf_document:
    toc: true
abstract: |
  BRGenomics is designed to help users avoid code repetition by providing efficient and tested functions to accomplish common, discrete tasks in the analysis of high-throughput sequencing data. The included functions are geared toward analyzing basepair-resolution sequencing data, the properties of which are exploited to increase performance and user-friendliness. We leverage standard Bioconductor methods and classes to maximize compatability with its rich ecoystem of bioinformatics tools, and we aim to make BRGenomics sufficient for most post-alignment data processing. Common data processing and analytical steps are turned into fast-running one-liners that can be simultaneously applied across numerous datasets. BRGenomics is fully-documented, and we aim it to be beginner-friendly.
  
vignette: |
  %\VignetteIndexEntry{Overview of BRGenomics}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

# Overview

## Motivation

This package is designed to:

* Replace the use of command-line utilities for most post-alignment processing, e.g. `bedtools` and `deeptools`
* Be easy-to-use and easy-to-install, without requiring external dependencies, e.g. `hitslib` or the kent source utilities from the UCSC genome browser
* Allow users to string together common analysis pipelines with simple, fast-running one-liners
* Avoid code repetition by providing tested and validated code
* Exploit the properties of basepair-resolution data to optimize performance and increase user-friendliness
* Use process forking to make use of multicore processors 
* Maximize compatability with Bioconductor's rich ecosystem of analysis software, in addition to leveraging the traditional strengths of R in statistics and data visualization
* Fully replace the `bigWig` R package

## Features

* Process and import bedGraph, bigWig, and bam files quickly and easily, with several pre-configured defaults for typical uses
* Count and filter spike-in reads
* Calculate spike-in normalization factors using several methods and options, including options for batch normalization
* Count reads by regions of interest
* Count reads at positions within regions of interest, at single-base resolution or in larger bins, and generate count matrices for heatmapping
* Calculate bootstrapped signal (e.g. readcount) profiles with confidence intervals (i.e. meta-profiles)
* Modify gene regions (e.g. extract promoters or genebody regions) using a single simple and straightforward function
* Conveniently and efficiently call `DESeq2` to calculate differential expression in a manner that is robust to global changes^[Avoid the default behavior of calculating genewise dispersion across all samples present, which is invalid if any experimental condition causes broad changes]
  + Use non-contiguous genes in `DESeq2` analysis, e.g. to exclude of specific sites/peaks from the analysis (not usually supported by DESeq2)
  + Efficiently generate results across a list of comparisons
* Support for blacklisting throughout, and proper accounting of blacklisted sites in relevant calculations
* Users interact with an intuitive and computationally efficient data structure (the "basepair resolution `GRanges`" object), which is already supported by a rich, user-friendly suite of tools that greatly simplify working with datasets and annotations

## Coming Soon

Data processing:

* Summarizing and plotting replicate correlations
* Function to use random read sampling to assess if sequencing depth sufficient to stabilize arbitrary calculations (so a user can supply anonymous function to calculate things like rank expression, power analysis or differential expression by DESeq2, pausing indices, etc.)

Signal counting and analysis:

* Two-stranded meta-profile calculations
* Automated generation of a list of DESeq2 comparisons using all possible combinations; all possible permutations; or by defining a simple hierarchy of each-vs-one comparisons


# Getting started

## Installation

Install development version from [GitHub](https://github.com/mdeber/BRGenomics):

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("mdeber/BRGenomics")
```

If you're using Windows, [Rtools for Windows](https://cran.rstudio.com/bin/windows/Rtools/) is required.

## Parallel Processing

By default, many BRGenomics functions will use multicore processing, as implemented in the `parallel` package, and the default is to use all available cores, as found using `detectCores()`. To meet the hosting requirements for Bioconductor, all code in the vignette and documentation is set to use no more than 2 cores, i.e. `ncores = 2`.

There is no support for parallel processing on Windows.

## Included Datasets

BRGenomics ships with an example dataset of PRO-seq data from Drosophila melanogaster^[Hojoong Kwak, Nicholas J. Fuda, Leighton J. Core, John T. Lis (2013). Precise Maps of RNA Polymerase Reveal How Promoters Direct Initiation and Pausing. _Science_  __339__(6122): 950â€“953. https://doi.org/10.1126/science.1229386]. PRO-seq is a basepair-resolution method that uses 3'-end sequencing of nascent RNA to map the locations of actively engaged RNA polymerases. 

To keep the dataset small, we've only included reads mapping to the fourth chromosome^[Chromosome 4 in Drosophila, often referred to as the "dot" chromosome, is very small and contains very few genes].

The included datasets can be accessed using the `data()` function:

```{r, message=FALSE}
library(BRGenomics)
```

```{r}
data("PROseq")
PROseq
```

Notice that the data is contained within a `GRanges` object. GRanges objects, from the `r Biocpkg("GenomicRanges")` package, are very easy to work with, and are supported by a plethora of useful functions and packages.

The structure of the data will be described later on (in section _"Basepair-Resolution GRanges Objects"_). For now, we'll just note that both annotations (e.g. genelists) and data are contained using the same GRanges class.

We've included an example genelist to accompany the PRO-seq data:

```{r}
data("txs_dm6_chr4")
txs_dm6_chr4
```

The GRanges above contains all Flybase annotated transcripts from chromosome 4, with no filtering of any kind.

## Basic Operations on GRanges

For users who are unfamiliar with GRanges objects, this section demonstrates a number of basic operations. 

A quick summary of the general strcture: Each element of a GRanges object is called a "range". As you can see above, each range consists of several components: `seqnames`, `ranges`, and `strand`. These essential attributes are all found to the left of the vertical divider above; everything to the right of that divider is an optional, metadata attribute. 

The core attributes can be accessed using the functions `seqnames()`, `ranges()`, and `strand()`. All metadata can be accessed using `mcols()`, and individual columns are accessable with the `$` operator. The only reserved metadata column is the `score` column, which is just like any other metadata column, except that users can use the `score()` function to assess it.

All of the above functions are both "getters" and "setters", e.g. `strand(x)` returns the strand information, and `strand(x) <- "+"` assigns it.

These and other operations are demonstrated below.

---

Get the length of the genelist:

```{r}
length(txs_dm6_chr4) 
```

Select the 2nd transcript:

```{r}
txs_dm6_chr4[2]
```

Select 4 transcipts:

```{r}
tx4 <- txs_dm6_chr4[c(1, 10, 200, 300)]
tx4
```

Get the lengths of the first 4 transcripts:

```{r}
width(tx4)
```

Get a dataframe of the metadata for the first 4 transcripts:

```{r}
mcols(tx4)
```

Access a single metadata column for the first 4 transcripts:

```{r}
mcols(tx4)[, 2]
mcols(tx4)[, "gene_id"]
tx4$gene_id
tx4_names <- tx4$tx_name
tx4_names
```

Get the first gene_id (a metadata element):

```{r}
tx4$gene_id[1]
```

Remove a metadata column:

```{r}
mcols(tx4) <- mcols(tx4)[, -1]
tx4
```

Rename metadata:

```{r}
names(mcols(tx4)) <- "gene_id"
tx4
```

Add metadata; same as access methods (`mcols()[]`, `mcols()$`, or simply `$`):

```{r}
tx4$tx_name <- tx4_names
tx4
```

Modify metadata:

```{r}
tx4$gene_id[1] <- "gene1"
tx4$tx_name <- 1:4
tx4
```

Get beginning of ranges (not strand specific):

```{r}
start(tx4)
```

Get beginning of ranges (strand specific):

```{r}
tx4_tss <- resize(tx4, width = 1, fix = "start")
tx4_tss
start(tx4_tss)
```

Remove all metadata:

```{r}
mcols(tx4) <- NULL
tx4
```

---

_To learn more about GRanges objects, including a general overview of their components, see the useful vignette [_An Introduction to the GenomicRanges Package_](https://bioconductor.org/packages/release/bioc/vignettes/GenomicRanges/inst/doc/GenomicRangesIntroduction.html). Alternatively, see the archived materials from the 2018 Bioconductor workshop [_Solving Common Bioinformatic Challenges Using GenomicRanges_](https://bioconductor.github.io/BiocWorkshops/solving-common-bioinformatic-challenges-using-genomicranges.html). Note that this package will implement and streamline a number of common operations, but users should still have a basic familiarity with GRanges objects._

---

# Importing & Modifying Genelists

## Importing Annotations with rtracklayer

Importing genomics files is accomplished using the `rtracklayer` package, which contains a variety of functions and options for importing and exporting.

```{r, eval = FALSE}
# import bed file
genelist <- import.bed("~/data/genelists/genes.bed")

# import gff
genelist <- import.gff("~/data/genelists/genes.gff")

# export a bed file after modifying
export.bed(genelist, "~/data/genelists/filtered_genes.bed")
```

## Defining Regions Using the genebodies Function

One of the more useful `GenomicRanges` functions is the `promoters` function, which returns ranges centered on the strand-specific start of the input ranges:

```{r}
tx4
tx4_pr <- promoters(tx4, upstream = 50, downstream = 100)
tx4_pr
width(tx4_pr)
```

BRGenomics ships with a more flexible alternative function called `genebodies`. While `promoters` has the arguments `upstream` and `downstream`, which take only positive values, the `genebodies` function uses `start` and `end` arguments that can be positive or negative, and arguments `fix.start` and `fix.end` for determining whether to define the positions in relation to the (strand-specific) beginning or ends of genes.

Below, we demonstrate several uses of the `genebodies` function, using a list of transcripts which start at a transcription start site (TSS) and end at a cleavage and polyadenylation site (CPS).

---

Original regions:

```{r}
tx4
```

Genebody regions from 300 bp downstream of the TSS to 300 bp upstream of the CPS:

```{r}
genebodies(tx4, 300, -300) 
```

Promoter regions from 50 bp upstream to 100 bp downstream of the TSS:

```{r}
genebodies(tx4, -50, 100, fix.end = "start")
```

_(The defaults are `fix.start = "start"` and `fix.end = "end"`)_

Regions from 100 bp upstream of to 50 bp upstream of the TSS:

```{r}
genebodies(tx4, -100, -50, fix.end = "start")
```

Regions from 1kb upstream of the CPS to 1kb downstream of the CPS

```{r}
genebodies(tx4, -1000, 1000, fix.start = "end")
```

Regions within the first 10kb downstream of the CPS:

```{r}
genebodies(tx4, 0, 10000, fix.start = "end")
```

# Basepair-Resolution GRanges Objects

Let's look again at the included PRO-seq data:

```{r}
PROseq
```

This GRanges object is constructed such that each range has a width of 1 (i.e. each range represents a single base in the genome), and each range has an associated `score`, which contains signal information for that base.

We refer to a GRanges object formatted in this way as a __basepair-resolution GRanges object__^[The `GPos` class is designed for a similar purpose, but we currently do not use it. There is a note on this in the documentation for `makeGRangesBRG`], and this structure underpins much of BRGenomics. 

In the included PRO-seq data, the positional information is determined by the 3' end of mapped reads, and the signal information is the number of reads containing that 3' end.

---

_bigWig files, as well as `coverage` objects in `GenomicRanges`, use a form of compression in which adjacent positions sharing the same signal are combined. For whole-read coverage methods, this run-length encoding enhances performance and efficiency. However, basepair resolution data is not nearly as smooth, and its rare that adjacent bases share the same signal. With basepair resolution data, combining adjacent positions increases complexity, while providing a negligible storage benefit._

---

Splitting up each base into its own range (its own index) results in a number of downstream computational benefits. Perhaps more importantly, however, is the added simplicity for the user: each index of a basepair-resolution GRanges object addresses a single genomic position and its associated signal. 

```{r, collapse=TRUE}
length(PROseq) # number of unique positions in dataset
sum(score(PROseq)) # total number of reads
sum(score(PROseq) == 1) # number of sites with only a single read
```

```{r}
subset(PROseq, score > 10) # sites with more than 10 reads
```

We can write a simple test to determine if a GRanges object is "basepair-resolution": all ranges have widths of 1, and no position is duplicated.

```{r, collapse=TRUE}
all(width(PROseq) == 1)
isDisjoint(PROseq) # [*]
```

_[*] A "disjoint" GRanges is one in which none of the ranges overlap one another._

For convenience, we've included a test function:

```{r}
isBRG(PROseq)
```

The next section, covering data importation, also serves to emphasize the characteristics of the basepair-resolution GRanges object, and demonstrates some alternatives that can be used within this pacakge.

# Importing and Processing Data

BRGenomics provides several functions for conveniently importing and processing BAM, bigWig, bedGraph files.

## Importing BAM Files

The `import_bam` function provides a number of options for filtering and processing bam files. BRGenomics includes an example BAM file with a small number of reads from the included PRO-seq data. The file's local location can be found (on your computer) as follows:

```{r}
bfile <- system.file("extdata", "PROseq_dm6_chr4.bam", 
                     package = "BRGenomics")
```

Because PRO-seq data is sequenced in the 3'-to-5' direction of the original RNA molecule, we'll use the `revcomp` option to reverse-complement all the input reads. We'll also set a minimum MAPQ score of 20:

```{r}
ps_reads <- import_bam(bfile, mapq = 20, revcomp = TRUE, paired_end = FALSE)
ps_reads
```

By default, `import_bam` combines identical reads into the same range, and the `score` metadata column indicatea the number of perfectly-overlapping alignments. This means that the total number of alignments (reads) is equal to the sum of 
the score:

```{r}
sum(score(ps_reads))
```

Alternatively, you can import each read as its own range by setting `field = NULL`:

```{r}
reads_expanded <- import_bam(bfile, mapq = 20, revcomp = TRUE, 
                             field = NULL, paired_end = FALSE)
ps_reads[1:8]
reads_expanded[1:8]
```

Notice that reads 5-7 are now identical, rather than combined into a single range with a score = 3.

```{r}
length(reads_expanded) == sum(score(ps_reads))
```

Many BRGenomics function have a `field` argument, and setting `field = NULL` will treat each range has a single read. 

## Example: Importing PRO-seq BAM files at Basepair Resolution

We can use the `import_bam` function to extract the positions of interest from BAM files. Below, we construct an import function for PRO-seq data that returns a basepair-resolution GRanges object.

In PRO-seq, a "run-on" reaction is performed in which actively engaged RNA polymerases incorporate a biotinylated nucleotide at the 3' end of a nascent RNA. Our base of interest is therefore the base immediately preceding the RNA 3' end, as this was the original position of a polymerase active site.

The processing options in `import_bam` are applied in the same order that they're listed (see the documentation). Following this order, we will apply the options:

1. Filter reads by a minimum MAPQ score 
2. Take the reverse complement
3. Shift reads upstream by 1 base
4. Extract the 3' base

```{r}
ps <- import_bam(bfile, 
                 mapq = 20, 
                 revcomp = TRUE,
                 shift = -1,
                 trim.to = "3p",
                 paired_end = FALSE)
ps
```

_Note that for paired-end data, `import_bam` will automatically filter unmatched read pairs._

Notice that the number of ranges in `ps` is not the same as for `ps_reads`, in which we imported the entire read lengths:

```{r, collapse = TRUE}
length(ps_reads)
length(ps)
```

This is because identical positions are collapsed together after applying the processing options. However, we can check that all of the same reads are represented:

```{r, collapse = TRUE}
sum(score(ps)) == sum(score(ps_reads))
```

And we can check that collapsing identical positions has created a basepair-resolution GRanges object:

```{r, collapse = TRUE}
isBRG(ps)
```

## Pre-formatted Input Functions

For convenience, we've included several functions with default options for several kinds of data, including `import_bam_PROseq`, `import_bam_PROcap`, and `import_bam_ATACseq`, the latter of which corrects for the 9 bp offset between Tn5 insertion sites.^[Jason D. Buenrostro, Paul G. Giresi, Lisa C. Zaba, Howard Y. Chang, William J. Greenleaf (2013). Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, dna-binding proteins and nucleosome position. \emph{Nature Methods} 10: 1213â€“1218. \url{https://doi.org/10.1038/nmeth.2688}]


## Example: Converting BAMs to bigWigs

In conjunction with export functions from the `r Biocpkg("rtracklayer")` package, we can use the functions described above to write a post-alignment pipeline for generating bigWig files for PRO-seq data:

```{r, eval=FALSE}
# import bam, automatically applying processing steps for PRO-seq
ps <- import_bam_PROseq(bfile, mapq = 30, paired_end = FALSE)

# separate strands, and make minus-strand scores negative
ps_plus <- subset(ps, strand == "+")
ps_minus <- subset(ps, strand == "-")
score(ps_minus) <- -score(ps_minus)

# use rtracklayer to export bigWig files
export.bw(ps_plus, "~/Data/PROseq_plus.bw")
export.bw(ps_minus, "~/Data/PROseq_minus.bw")
```

An expanded example pipeline is included later in the vignette.

## Importing bedGraphs and bigWigs

bedGraph and bigWig files are efficient and portable, but unstranded representations of basepair-resolution genomics data. 

As compared to `rtracklayer::import.bedGraph`, the BRGenomics function `import_bedGraph` imports both plus-strand and minus-strand files as a single object, and has options for filtering out odd chromosomes, mitochondrial chromosomes, and sex chromosomes.

```{r}
# local paths to included bedGraph files
bg.p <- system.file("extdata", "PROseq_dm6_chr4_plus.bedGraph",
                    package = "BRGenomics")
bg.m <- system.file("extdata", "PROseq_dm6_chr4_minus.bedGraph",
                    package = "BRGenomics")

import_bedGraph(bg.p, bg.m, genome = "dm6")
```

The `import_bigWig` function provides the same functionality on top of `rtracklayer::import.bw`, but also removes run-length compression and returns a basepair-resolution GRanges object.

```{r}
# local paths to included bigWig files
bw.p <- system.file("extdata", "PROseq_dm6_chr4_plus.bw",
                    package = "BRGenomics")
bw.m <- system.file("extdata", "PROseq_dm6_chr4_minus.bw",
                    package = "BRGenomics")

import_bigWig(bw.p, bw.m, genome = "dm6")
```

# Signal Counting

## Signal by Region

The `getCountsByRegion` function counts signal within regions of interest, and returns a simple vector. For instance, we can count PROseq signal within our transcripts:

```{r, collapse = TRUE}
counts_txs <- getCountsByRegions(PROseq, txs_dm6_chr4)
counts_txs[1:5]
length(txs_dm6_chr4) == length(counts_txs)
```

## Signal by Position and Region

The `getCountsByPositions` function will count signal at each position within each region of interest. By default, a matrix is returned, with a row for each region, and a column for each position.

```{r}
# get first 100 bases of each transcript
txs_pr <- promoters(txs_dm6_chr4, 0, 100)
# get signal at each base within each promoter region
countmatrix_pr <- getCountsByPositions(PROseq, txs_pr)
```

```{r, collapse = TRUE}
class(countmatrix_pr)
nrow(countmatrix_pr) == length(txs_pr)
ncol(countmatrix_pr) == width(txs_pr[1])
```

By default, each "position" (each column) is a single base, but counting can be done in bins as well:

```{r}
# get signal in 10 bp bins within each promoter region
countmatrix_pr_bin <- getCountsByPositions(PROseq, txs_pr, binsize = 10)
countmatrix_pr_bin[1:5, ]
```

```{r, collapse = TRUE}
all(rowSums(countmatrix_pr_bin) == rowSums(countmatrix_pr))
```

By default, an error is returned if input regions aren't all the same size:

```{r, error = TRUE}
getCountsByPositions(PROseq, txs_dm6_chr4)
```

An error is returned by default to avoid accidental use of `getCountsByPositions` in lieu of `getCountsByRegions`. However, for the rare case when users do intend to use multi-width regions, there is support for this using the `simplify.multi.widths` argument, which contains several useful options for how to do this (see the documentation for more details).

## Example: Plot Signal Over a Gene

We can use `getCountsByPositions` to get the signal profile over a single gene. Let's have a look at the gene with the highest signal near the TSS:

```{r, collapse = TRUE}
idx <- which.max(rowSums(countmatrix_pr))
idx

plot(x = 1:ncol(countmatrix_pr), 
     y = countmatrix_pr[idx, ], 
     type = "h", 
     main = txs_pr$tx_name[idx],
     xlab = "Distance to TSS",
     ylab = "PRO-seq Signal")
```

## Example: Plot Signal Heatmap

A typical use of `getCountsByPositions` is to generate a heatmap of signal by position within a list of genes. The `ComplexHeatmap` package is well documented and offers a high level of functionality, but we can also use `ggplot2` to generate customizable heatmaps. 

To format our matrix for ggplot, we want to "melt" it. The package `reshape2` can melt matrices into dataframes, but BRGenomics also provides a `melt` argument for several functions, including `getCountsByPositions`:

```{r}
cbp.df <- getCountsByPositions(PROseq, txs_pr, binsize = 10, melt = TRUE,
                               ncores = 2)
head(cbp.df)
```

As you can see, the rows and columns of the matrix are now described in columns of this dataframe, and the signal held at each position is in the third column. Now we can plot:

```{r}
library(ggplot2)
```

```{r}
ggplot(cbp.df, aes(x = 10*position - 5, y = region, fill = signal)) + 
  geom_raster() + 
  coord_cartesian(expand = FALSE) + 
  labs(x = "Distance from TSS", y = "Transcript", 
       title = "PRO-seq", fill = "Reads") + 
  theme_bw()
```

# Efficient Analysis of Multiple Datasets

To efficiently work with several datasets, we recommend storing the GRanges objects within a standard, named list, e.g. `grl <- list(a_rep1 = gr1, b_rep1 = gr2, ...)`.

```{r}
# make 3 datasets
ps1 <- PROseq[seq(1, length(PROseq), 3)]
ps2 <- PROseq[seq(2, length(PROseq), 3)]
ps3 <- PROseq[seq(3, length(PROseq), 3)]

# use the "=" assignment in list() to give names to the list elements
ps_list <- list(ps1 = ps1, ps2 = ps2, ps3 = ps3)
names(ps_list)
ps_list
```

A named list like the one above can be passed as an argument to nearly every function in BRGenomics, and many functions will automatically return dataframes, or melted dataframes that use the list names as the sample names (which can simplify plotting with `ggplot2` or `lattice`).

_Note that BRGenomics does not currently support the use of `GRangesList` or `CompressedGRangesList` classes for grouping multiple datasets._^[The `GRangesList` and `CompressedGRangesList` classes, particularly the latter, often cause performance penalties. Support may be added in the future.]

## Example: Summarizing Signal from Multiple Samples

We can pass our list of GRanges directly to `getCountsByRegions` to simultaneously count reads for each dataset, and melt the result for plotting with `ggplot`:

```{r}
getCountsByRegions(ps_list, txs_dm6_chr4[1:5], ncores = 1)
```

```{r}
# melt, and use the optional region_names argument
txs_counts <- getCountsByRegions(ps_list, txs_dm6_chr4, melt = TRUE,
                                 region_names = txs_dm6_chr4$tx_name,
                                 ncores = 1)
head(txs_counts)
```

```{r}
library(ggplot2)
ggplot(txs_counts, aes(x = sample, y = signal, fill = sample)) + 
  geom_violin() + 
  theme_bw()
```

## Example: Making Browser Shots in R

Plotting signal over a single locus for several datasets, we can use `getCountsByPositions` to bake our own genome browser shots within R. Using the same region we plotted earlier:

```{r}
cbp_maxtx <- getCountsByPositions(ps_list, txs_dm6_chr4[idx], 
                                  melt = TRUE, ncores = 2)
head(cbp_maxtx)
```

```{r, fig.height=4, fig.width=6}
ggplot(cbp_maxtx, aes(x = position, y = signal)) + 
  facet_wrap(~sample, ncol = 1, strip.position = "left") + 
  geom_col(size = 0.5, color = "darkgray") +
  labs(title = txs_dm6_chr4$tx_name[idx],
       x = "Distance from TSS", y = "PRO-seq Signal") + 
  theme_bw()
```

The `Gviz` package contains a good deal browser-oriented plotting functionality, like plotting gene models.

## Multiplexed GRanges

There is another data structure that is widely supported with BRGenomics, called a __multiplexed GRanges__. A multiplexed GRanges is a single GRanges object that contains multiple metadata fields containing basepair-resolution coverage data for different datasets. We currently recommend users use lists of GRanges objects, but you might find that multiplexed GRanges objects have performance benefits for your data (notes on this below).

A multiplexed GRanges object can be made using the `mergeGRangesData` with option `multiplex = TRUE`.

```{r}
ps_multi <- mergeGRangesData(ps1, ps2, ps3, multiplex = TRUE, ncores = 2)
ps_multi
```

As in any GRanges object, the metadata fields are accessible as a dataframe with the `mcols()` function, and individual columns are accessible with the `$` operator.^[The dataframe, by default, is not a base R `data.frame`, but rather an S4 `DataFrame`. The distinction isn't important for end users, and it's unlikely users will encounter any reason to coerce the class using `as.data.frame`.]

```{r}
mcols(ps_multi)
```

```{r, collapse = TRUE}
ps_multi$ps1[1:5]
```

This data structure can be passed to most functions in BRGenomics. To be explicit, users should set the `field` argument, when it exists, to set the datasets for which calculations should be performed:

```{r}
# for all datasets (all fields), get counts in the first 5 transcripts
getCountsByRegions(ps_multi, txs_dm6_chr4[1:5], field = names(mcols(ps_multi)),
                   ncores = 2)

# get counts for ps2 dataset only
getCountsByRegions(ps_multi, txs_dm6_chr4[1:5], field = "ps2", ncores = 2)

# if no field is given, most functions will default to using all fields
getCountsByRegions(ps_multi, txs_dm6_chr4[1:5], ncores = 2)
```

In our experience with PRO-seq data, and to our surprise, a list of GRanges objects typically outperforms multiplexed GRanges on a typical laptop, despite the theoretical benefits of multiplexing. 

---

_In principle, the multiplexed GRanges structure is designed to reduce memory usage and increase performance, but this has not been our experience when dealing with sparse, basepair-resolution data like PRO-seq. Overlapping signal with regions of interest (e.g. in `getCountsByRegions` or `getCountsByPosition`) is relatively efficient for reasonably sized GRanges objects, and these calculations scale reasonably well with multicore processing. While multiplexing means that signal overlapping only has to be performed once, we've found that this is a relatively small benefit in practice that is easily offset by having to do signal calculations on large sparse vectors of signal counts. However, the relative benefits of using lists or multiplexing are likely to depend on the nature of the data being analyzed, as well as well as computer hardware._

---

# Saving Binary R Files

While the handling of GRanges data in BRGenomics is relatively fast, the initial importation of bigWig or bedGraph files as GRanges objects remains a noticeable bottleneck. This may be tolerable for interactive workflows, in which data is imported once before undergoing lengthy analysis, but the bottleneck is a significant detriment for users who regularly import data.

To avoid this bottleneck, users can save reusable data structures as binary R files, which effectively save the memory state of R objects. Not only are these objects rapidly reloaded into memory upon importation, but they have the added benefit of saving the user from repeating data formatting.

Any R object can be saved to storage using the `saveRDS` function, and re-imported using `readRDS`. 

```{r, eval = FALSE}
# save the PRO-seq GRanges for later import
saveRDS(PROseq, file = "~/PROseq.RData") 

# save a list of GRanges
saveRDS(ps_list, file = "~/ps_list.RData")

# re-import
ps_list <- readRDS("~/ps_list.RData")
```

The `save` and `load` commands can also be used to accomplish the same thing, although they work slightly differently.^[Unlike the `saveRDS`/`readRDS` commands, the `read`/`load` commands maintain the original name of the objects. For instance, if you `save(PROseq, file = "~/ps.RData")`, and in a new R session run `read("~/ps.RData")`, a new object called `PROseq` will be created in your new environment. (Note that this is the same way that RStudio saves your current working environment to disk, i.e. it saves the entire environment into an RData file, which can then be reloaded, remaking every data object).]

# Profile Plots & Bootstrapping

## Conventional Profiles

As an example, we'll plot PRO-seq signal in promoter-proximal regions by calculating the mean signal intensity at each base in the first 100 bases of a transcript.

First, calculate signal at each base for all promoter-proximal regions:

```{r, collapse = TRUE}
countmatrix_pr <- getCountsByPositions(PROseq, txs_pr, ncores = 2)
dim(countmatrix_pr)
dim(countmatrix_pr) == c(length(txs_pr), unique(width(txs_pr)))
```

For each position (each column of the matrix), calculate the mean, and plot:

```{r}
plot(x = 1:ncol(countmatrix_pr),
     y = colMeans(countmatrix_pr),
     type = "l", 
     xlab = "Distance to TSS (bp)",
     ylab = "Mean PRO-seq Reads")
```

One drawback of using the arithmatic mean is that means are not robust to outliers. In other words, the mean signal at any position is liable to be determined by a small number of highly influential points. This is especially problematic for high dynamic range data like PRO-seq.

It's common to see this issue addressed through the use medians/quantiles in place of arithmatic means. However, observe what happens as we plot the median signal across our gene list using several different gene-filtering thresholds:

```{r, fig.height=7, fig.width=6}
plot_meds <- function(sig_thresh) {
  idx <- which(rowSums(countmatrix_pr) > sig_thresh)
  plot(x = 1:ncol(countmatrix_pr),
       y = apply(countmatrix_pr[idx, ], 2, median),
       type = "l", 
       main = sprintf("Regions with >%s reads", sig_thresh),
       xlab = "Distance to TSS (bp)",
       ylab = "Median PRO-seq Reads")
}

par(mfrow = c(3, 2))

for (i in c(0, 30*2^(0:4))) {
  plot_meds(i)
}
```

The paucity of transcription on Drosophila chromosome 4 makes this a somewhat extreme example, and you might find that the above situation is a non-issue for your data. However, it's important to keep in mind how unexpressed genes can affect the median. A common rule of thumb is that a given cell is only apt to express around half of its genes; if that holds true, the median of an unfiltered genelist will be close to zero, and could be insensitive to changes occuring at expressed genes. 

## The Rationale for Bootstrapping 

A robust alternative to plotting mean or median signal profiles is to plot __bootstrapped__ mean signal profiles, known as metaprofile plots or metaplots. 

To bootstrap the mean signal by position, a small number of genes are randomly sampled from a genelist, and the mean signal at each position is calculated for that group of genes. This process of randomly sampling genes and calculating mean signals is repeated over many iterations, and the final bootstrapped mean for each position is the median of the sampled means.

One feature of bootstrapping is that it is robust to outliers. But more than that, the a bootstrapped mean provides an _expectation_ for what the mean signal would be for any arbitrary group of genes, and associated with that expectation is a measure of uncertainty. By taking quantiles of the subsampled means _other than_ the median (the expected value), we can estimate the extent to which the mean varies across arbitrary groups of genes. 

For example, the 75th percentile of the subsampled means is a number for which, 25% of the time, we calculated a higher mean. Similarly, a 90% confidence interval about the bootstrapped mean encompasses all values between the 5th and 95th percentiles of the subsampled means.

## Generating and Plotting Metaprofiles

We can use the `metaSubsample` function to bootstrap mean values by position for a genelist. The function accepts the same arguments as `getCountsByPositions`, in addition to other arguments related to the bootstrapping. 

By default, 10% of the genelist is randomly sampled 1000 times, and confidence bands are returned for the 12.5th and 87.5th percentiles (i.e. a 75% confidence interval). 

Given the small size our dataset, we'll reduce this to a 30% confidence interval, and we'll additionally use 5 bp bins:

```{r}
bootmeans.df <- metaSubsample(PROseq, txs_pr, binsize = 5, 
                              lower = 0.35, upper = 0.65, ncores = 2)
head(bootmeans.df)
```

A dataframe is returned for plotting, and notice how the x-values have been automatically adjusted to be the center of the bins.

Below, we show how to plot the confidence bands using base R plotting, as well as `ggplot2`.

```{r}
plot(mean ~ x, data = bootmeans.df, type = "l", 
     main = "PRO-seq Signal", ylim = c(0, 1.4),
     xlab = "Distance from TSS",
     ylab = "Mean Signal + 30% CI")

# draw a polygon to add confidence bands,
# and use adjustcolor() to add transparency
polygon(c(bootmeans.df$x, rev(bootmeans.df$x)), 
        c(bootmeans.df$lower, rev(bootmeans.df$upper)),
        col = adjustcolor("black", 0.1), border = FALSE)
```

```{r}
require(ggplot2)
ggplot(bootmeans.df, aes(x, mean)) + 
  geom_line() + 
  geom_ribbon(aes(x, ymin = lower, ymax = upper),
              alpha = 0.1) + 
  labs(title = "PRO-seq Signal", 
       x = "Distance from TSS", 
       y = "Mean Signal + 30% CI") + 
  theme_bw()
```

## Example: Comparative Metaplots

Like other functions in BRGenomics, we can pass a list of GRanges to `metaSubsample`, and the output is conveniently combined for plotting.

```{r}
bm_list.df <- metaSubsample(ps_list, txs_pr, binsize = 5, 
                            lower = 0.35, upper = 0.65, ncores = 2)
head(bm_list.df)
```

```{r}
require(ggplot2)
ggplot(bm_list.df, aes(x, mean, color = sample.name)) + 
  geom_line() + 
  geom_ribbon(aes(x, ymin = lower, ymax = upper,
                  color = NULL, fill = sample.name),
              alpha = 0.2) + 
  labs(title = "PRO-seq Signal", 
       x = "Distance from TSS", 
       y = "Mean Signal + 30% CI") + 
  theme_bw()
```

_Bear in mind that the above confidence intervals are ignoring 70% of the subsampling experiments, which is excessive. More reasonable parameters would reveal how lacking this data is, i.e. how un-confident we are that there is a robust difference in the mean signal at various positions._ 

# Spike-in Normalization

BRGenomics includes useful utilities for spike-in normalization. 

A typical approach is to add the spike-in (either exogenous cells or synthetic oligonucleotides) before library preparation, and to subsequently map to a __combined genome__ containing both the target organisms chromosomes (to map the experimental reads) as well as sequences/chromosomes for the spike-in. 

This so-called "competitive alignment" results in the creation of BAM files containing a mix of chromosomes, for which it should be straightforward to identify the spike-in chromosomes.

## Counting Spike-in Reads

```{r, echo = FALSE}
gr1_rep1 <- GRanges(seqnames = c("chr1", "chr2", "spikechr1", "spikechr2"),
                    ranges = IRanges(start = 1:4, width = 1),
                    strand = "+")
gr2_rep2 <- gr2_rep1 <- gr1_rep2 <- gr1_rep1

# set readcounts
score(gr1_rep1) <- c(1, 1, 1, 1) # 2 exp + 2 spike = 4 total
score(gr2_rep1) <- c(2, 2, 1, 1) # 4 exp + 2 spike = 6 total
score(gr1_rep2) <- c(1, 1, 2, 1) # 2 exp + 3 spike = 5 total
score(gr2_rep2) <- c(4, 4, 2, 2) # 8 exp + 4 spike = 12 total

grl <- list(gr1_rep1, gr2_rep1,
            gr1_rep2, gr2_rep2)

names(grl) <- c("gr1_rep1", "gr2_rep1",
                "gr1_rep2", "gr2_rep2")
```

For this section, we'll use a list of 4 dummy datasets containing normal, as well as spike-in chromosomes. Consider the first 2 datasets:

```{r}
grl[1:2]
```

We can identify the spike-in chromosomes either by full names, or by a regular expression that matches the spike-in chromosomes. In this case, we named our spike-in chromosomes to contain the string "spike" which makes them easy to identify. 

To count the reads for each dataset:

```{r}
getSpikeInCounts(grl, si_pattern = "spike", ncores = 2)
```

## Filtering Spike-in Reads

We can also remove the spike-in reads from our data:

```{r}
removeSpikeInReads(grl[1:2], si_pattern = "spike", ncores = 2)
```

And if we wanted to isolate the spike-in reads, there is an analagous `getSpikeInReads` function.

## The Spike-in Normalization Factor

There are several methods by which to generate spike-in normalization factors, but we advocate for a particular method, which generates units we call <b>S</b>pike-in normalized <b>R</b>eads <b>P</b>er <b>M</b>illion mapped reads in the negative <b>C</b>ontrol (<b>SRPMC</b>). The SRPMC normalization factor for a given sample $i$ is defined as such:

$$SRPMC:\ NF_i = \frac{\sum reads_{spikein, control}}{\sum reads_{spikein, i}} 
\cdot \frac{10^6}{\sum reads_{experimental, control}}$$

This expression effectively calculates Reads Per Million (RPM) normalization for the negative control, and all other samples $i$ are scaled into equivalent units according to the ratio of their spike-in reads. We provide a more explicit derivation below.

### Derivation of SRPMC

The fundamental concept of spike-in normalization is that the ratio of experimental reads to spike-in reads can be used to correct for global changes in starting material. Let's call this ratio <u>R</u>eads <u>P</u>er <u>S</u>pike-in read (<b>RPS</b>):

$$RPS = \frac{\sum reads_{experimental}}{\sum reads_{spikein}}$$

In isolation, this number only reflects the relative amounts of spike-in material recovered and mapped. The meaningful information about changes in material can only arise from making direct comparisons between samples. For any sample, $i$, we can calculate the global change in signal as a proportion of the material recovered from a negative control:

$$RelativeSignal_i = \frac{RPS_i}{RPS_{control}}$$

The usual purpose of spike-in normalization is to measure a biological difference in total material (e.g. RNA) between samples, and the above ratio is a direct measurement of this.

To generate normalization factors, we use the above ratio to adjust RPM (Reads Per Million mapped reads) normalization factors, which we define below for clarity:

$$RPM:\ NF_i = \frac{1}{\frac{\sum{reads_i}}{10^6}} = \frac{10^6}{\sum{reads_i}}$$

(Unless indicated, $reads$ refers to non-spike-in reads).

RPM normalization (i.e. read depth normalization) is the simplest and likely most familiar form of normalization. For a basal (unperturbed) negative control, RPM should produce the most portable metric of signal, given that we intend for the negative control to demonstrate typical physiology, and we hope that this state is reproducible. We therefore want to have our normalized signal in unit terms of RPM in the negative control.

To accomplish this, we multiply the ratio of spike-in normalized reads between the sample $i$ and the negative control to the RPM normalization factor for sample $i$. This converts readcounts into units we summarize as <u>S</u>pike-in normalized <u>R</u>eads <u>P</u>er <u>M</u>illion mapped reads in the negative <u>C</u>ontrol (SRPMC):

$$SRPMC:\ NF_i = \frac{RPS_i}{RPS_{control}} \cdot \frac{10^6}{\sum{reads_i}}$$

Again, SRPMC results in the negative control being RPM (sequencing depth) normalized, while all other samples are in equivalent, directly comparable units. And we've effectively determined the relative scaling of those samples based on the ratios of spike-in reads.

This becomes more apparent if we substitute the $RPS$ variables above. $\sum{reads_i}$ cancels, and simplifying the fraction produces the original formula:

$$SRPMC:\ NF_i = \frac{\sum reads_{spikein, control}}{\sum reads_{spikein, i}} 
\cdot \frac{10^6}{\sum reads_{experimental, control}}$$

## Calculating Normalization Factors

We can calculate SRPMC normalization factors for each sample using the `getSpikeInNFs` function, using the same syntax we used to count the spike-in reads. 

However, we have to also identify the negative control, which is the sample that will have the "reference" (RPM) normalization. We do this either using a regular expression (`ctrl_pattern` argument) or by supplying the name(s) of the negative controls (the `ctrl_names` argument). 

The default method is "SRPMC", but there are other options, as well.

```{r}
getSpikeInNFs(grl, si_pattern = "spike", ctrl_pattern = "gr1", ncores = 2)
```

(The NFs are high because our dummy data contain only a few reads).

By default, normalization factors utilize __batch normalization__, such that in any replicate (identified by the characters following "rep" in the sample names), the negative control is RPM normalized, and the other conditions are normlized to the within-replicate negative control (see the documentation for further details).

Currently, batch normalization requires the sample names end with strings matching the format `"_rep1"`, `"_rep2"`, etc. If sample names do not conform to this pattern, you can rename them by using the `sample_names` argument.

## Normalizing Data

We can also use the `spikeInNormGRanges` function to simultaneously find the spike-in reads, calculate the spike-in normalization factors, filter out spike-in reads, and normalize the readcounts:

```{r}
spikeInNormGRanges(grl, si_pattern = "spike", ctrl_pattern = "gr1", ncores = 2)
```

# Normalization by Subsampling 

## Rationale

When viewing genomics data in a genome browser (or otherwise plotting signal for a single gene), the sparsity of basepair resolution data can challenge our visual perception. 

Consider two datasets from identical samples, but where one is sequenced to a higher depth. The two datasets can be normalized such that the signal counts are equivalent, but the dataset with higher sequencing depth will have also uncovered additional sites. When plotted in a genome browser, the total signal within a region may be the same, but the more highly sequenced dataset will cover more positions but have lower peaks, while the less sequenced dataset will look sparse and spikey in comparison.

Below, we compare PRO-seq data derived from the same dataset over the same gene. In one case, we randomly sample half of the reads over that gene, while in another, we divide all the readcounts by 2.

```{r}
# choose a single gene
gene_i <- txs_dm6_chr4[185]
reads.gene_i <- subsetByOverlaps(PROseq, gene_i)

# sample half the raw reads
set.seed(11)
sreads.gene_i <- subsampleGRanges(reads.gene_i, prop = 0.5, ncores = 2)

# downscale raw reads by a factor of 2
score(reads.gene_i) <- 0.5 * score(reads.gene_i)
```

```{r, collapse = TRUE}
sum(score(reads.gene_i))
sum(score(sreads.gene_i))
```

```{r, results = "hold"}
plot(x = 1:width(gene_i), 
     y = getCountsByPositions(sreads.gene_i, gene_i),
     type = "h", ylim = c(0, 20),
     main = "PRO-seq (downsampled)",
     xlab = "Distance from TSS", ylab = "Downsampled PRO-seq Reads")

plot(x = 1:width(gene_i), 
     y = getCountsByPositions(reads.gene_i, gene_i),
     type = "h",  ylim = c(0, 20),
     main = "PRO-seq (downscaled)", 
     xlab = "Distance from TSS",  ylab = "Downscaled PRO-seq Reads")
```

The two plots above come from the same data, and contain the same quantity of signal, but their profiles are notably distinct. Particularly when plotting many samples over large regions within a genome browser, differences caused by sequencing depth can be misleading. It can be challenging to estimate differences if some datasets are "tall and spikey" while others are "short and smooth".

Absent global changes in signal, the above scenario can be resolved beforehand by equal sequencing depths, or by down-sampling to match readcounts. 

However, matching raw readcounts is not a solution when significant biological changes in total signal should be accounted for. 

For instance, consider an example in which there is a true, two-fold biological difference in transcription between two samples. If we could avoid all technical artifacts and measure the transcription directly in each individual cell, we would expect to uncover half the number of transcribing complexes in the lower condition. Having equivalent sequencing depth across those two conditions is effectively a technical artifact, and down-scaling the signal by multiplication can cause the visual challenges observed above.

## Subsampling for Normalization

To address the above concerns, we've included a function `subsampleBySpikeIn` to randomly sample reads to match the normalized signal proportions between datasets.

Internally, the function uses the `getSpikInNFs` function, but instead of SRPMC normalization, using the option `method = "SNR"`, which calculates normalization factors that downscale each dataset to match the dataset with the least spike-in reads. From this, the number of "desired reads" is established for each dataset, and subsequently that number of reads is randomly sampled.

```{r}
removeSpikeInReads(grl, si_pattern = "spike", ncores = 2)
getSpikeInNFs(grl, si_pattern = "spike", method = "SNR", batch_norm = FALSE,
              ncores = 2)
subsampleBySpikeIn(grl, si_pattern = "spike", batch_norm = FALSE, ncores = 2)
```

Normalization by subsampling sacrifices information to reduce biases across datasets.

# Example: Comprehensive BAM to bigWig Pipeline

Below, we use many of the functions described above to generate several sets of bigWig files for a number of datasets.

_[Coming soon]_


# Using DESeq2 for Pairwise Differential Expression

## Rationale 

DESeq2's default treatment of data relies on the assumption that genewise estimates of dispersion are largely unchanged across samples. While this assumption holds for a typical RNA-seq data, it can be violated if there are samples within the `DESeqDataSet` object for which there are meaningful signal changes across a majority of regions of interest. 

The BRGenomics functions `getDESeqDataSet` and `getDESeqResults` are simple and flexible wrappers for making pairwise comparisons between individual samples, without relying on the assumption of globally-similar dispersion estimates. In particular, `getDESeqResults` follows the logic that the presence of a dataset $X$ within the `DESeqDataSet` object will not affect the comparison of datasets $Y$ and $Z$.

While the intuition above is appealing, users should note that if the globally-similar dispersions assumption _does_ hold, then DESeq2's default behavior should be more sensitive in its estimates of genewise dispersion. In this case, users can still take advantage of the convenience of the BRGenomics function `getDESeqDataSet`, but they should subsequently call `DESeq2::DESeq` and `DESeq2::results` directly.

If the globally-similar dispersions assumption is violated, but something beyond simple pairwise comparisons is desired (e.g. group comparisons or additional model terms), we note that, with some prying, DESeq2 can be used without "blind dispersion estimation" (see the DESeq2 manual).

## Getting DESeq Results

Just like the functions that generate batch-normalized spike-in normalization factors, the DESeq-oriented functions require that the names of the input datasets end in `"rep1"`, `"rep2"`, etc. 

We'll use another list of GRanges here, in order to have multiple comparisons to make:

```{r, echo = FALSE}
make_pslist <- function() {
  ps_a_rep1 <- PROseq[seq(1, length(PROseq), 6)]
  ps_b_rep1 <- PROseq[seq(2, length(PROseq), 6)]
  ps_c_rep1 <- PROseq[seq(3, length(PROseq), 6)]
  ps_a_rep2 <- PROseq[seq(4, length(PROseq), 6)]
  ps_b_rep2 <- PROseq[seq(5, length(PROseq), 6)]
  ps_c_rep2 <- PROseq[seq(6, length(PROseq), 6)]
  
  list(A_rep1 = ps_a_rep1, A_rep2 = ps_a_rep2,
       B_rep1 = ps_b_rep1, B_rep2 = ps_b_rep2,
       C_rep1 = ps_c_rep1, C_rep2 = ps_c_rep2)
}
ps_list2 <- make_pslist()
```

```{r}
ps_list2[1:2]
names(ps_list2)
```

As you can see, the names all end in "repX", where X indicates the replicate. Replicates will be grouped by anything that follows "rep". If the sample names do not conform to this standard, the `sample_names` argument can be used to rename the samples within the call to `getDESeqDataSet`.

However, since our sample names conform, we won't use that argument:

```{r}
dds <- getDESeqDataSet(ps_list2, txs_dm6_chr4,
                       gene_names = txs_dm6_chr4$gene_id,
                       ncores = 2)
dds
```

Notice that the `dim` attribute of the `DESeqDataSet` object is `c(111, 6)`. There are 6 samples, but `length(txs_dm6_chr4)` is not 111. This is because we provided gene names to `getDESeqDataSet`, which were non-unique. The feature being exploited here is for use with __discontinuous gene regions__, _not for multiple overlapping transcript isoforms_. Options addressing this may be added in the future, but for the time being, users should be careful when double-counting reads.

We could have added normalization factors, which DESeq2 calls "size factors", in the call to `getDESeqDataSet`, or we can supply them to `getDESeqResults` below. (Supplying them twice will overwrite the previous size factors). 

---

__Note:__ DESeq2 size factors are the _inverse_ of BRGenomics normalization factors. So if you calculate normalization factors with `NF <- getSpikeInNFs(...)`, set `sizeFactors <- 1/NF`.

---

Generating DESeq2 results is simple:

```{r}
getDESeqResults(dds, contrast.numer = "B", contrast.denom = "A",
                quiet = TRUE, ncores = 2)
```

We can also make multiple pairwise-comparisons by ignoring the `contrast.numer` and `contrast.denom` arguments, and instead using the `comparisons` argument. The resulting list of results is named according to the comparisons:

```{r}
dsres <- getDESeqResults(dds, comparisons = list(c("B", "A"), 
                                                 c("C", "A"),
                                                 c("C", "B")),
                         quiet = TRUE, ncores = 2)
names(dsres)
dsres$C_vs_B
```

# Blacklisting

Many functions in BRGenomics support blacklisting, or the exclusion of certain sites from analysis. To use this feature, import your blacklist as a GRanges object, and use the blacklist option.

For instance, `getCountsByPositions()` supports blacklisting, and there is an additional option of whether to set all blacklisted sites to 0 counts, or to set those sites equal to NA. Setting them to NA is useful, as many functions have arguments to ignore NA values in calculations, i.e. `mean(x, na.rm = TRUE)`.

Supplying a blacklist to `metaSubsample()` will result in blacklisted positions being ignored in the calculations. Regions for which some section overlaps the blacklist are not ignored entirely, but the blacklisted positions themselves won't contribute to the calculations. 

# Merging GRanges Data

Biological replicates are best used to independently reproduce and measure effects, and therefore we often want to handle them separately. However, there are times when combining replicates can allow for more sensitive measurements, assuming that the replicates are highly concordant.

The `mergeGRangesData` function can be used to combine basepair-resolution GRanges objects:

```{r, collapse = TRUE}
length(ps1)
length(ps2)
length(ps3)
```

```{r}
merge_ps <- mergeGRangesData(ps1, ps2, ps3, ncores = 2)
merge_ps
```

Note that the output is also a basepair-resolution GRanges object.

```{r, collapse = TRUE}
isBRG(merge_ps)
```

We could have also passed a list of GRanges objects directly as an argument:

```{r}
mergeGRangesData(ps_list, ncores = 2)
```

# Sequence Extraction

In this section, we'll give one more example showing the benefit of Bioconductor integration by using the `Biostrings` package to extract sequences given by GRanges objects.

```{r, message = FALSE}
library(Biostrings)
```

We've included a twobit file of sequences, although users can use fasta files, as well.

```{r}
# get path to included 2bit file
sfile <- system.file("extdata", "dm6_chr4chrM.2bit",
                     package = "BRGenomics")
```

We could import the entire sequence using the rtracklayer `import()` function, which will figure out the file format and import a suitable object. In this case, a `DNAStringSet`:

```{r}
seq_chr4 <- import(sfile)
seq_chr4
```

_We included mitochondrial DNA to demonstrate how the DNAStringSet treats multiple chromosomes._

However, we don't need to import all the sequences. Instead, we can make a `TwoBitFile` object that points to the file, and extract desired sequences from it directly using the `getSeq` function:

```{r}
seq_txs_pr <- getSeq(TwoBitFile(sfile), txs_pr)
seq_txs_pr
```

The sequences are stranded as well, such that if a plus and minus strand gene overlapped perfectly, the minus strand sequence would be the reverse complement of the plus strand sequence.

The Biostrings package itself is richly featured, and we'll demonstrate only a couple functions below. This functionality is extended by packages like `ggseqlogo`, for example, which plots sequence logos directly from DNAStringSets.

```{r}
RNAStringSet(seq_txs_pr)
suppressWarnings(translate(seq_txs_pr))
oligonucleotideFrequency(seq_txs_pr[1:5], width = 1)
oligonucleotideFrequency(seq_txs_pr[1:5], width = 2)
```

```{r}
tss_seq <- getSeq(TwoBitFile(sfile), promoters(txs_pr, 4, 4))
tsspwm <- PWM(tss_seq)
tsspwm
```

# Session info {.unnumbered}

```{r sessionInfo, echo=FALSE}
devtools::session_info()
```


<!-- SCRAP -->

<!-- The `import_bam` function provides several options for processing aligned reads, and in conjunction with functions from the `r Biocpkg("rtracklayer")` package, we can easily write a post-alignment pipeline for generating bigWig files for viewing in a genome browser. -->

<!-- As an exmaple, PRO-seq data is sequenced in the antisense orientation to the original RNA molecule, the 3' end of which provides the location of the active site of an engaged RNA polymerase. Therefore, PRO-seq reads need to be reverse-complemented, and the 3' ends need to be extracted. -->
